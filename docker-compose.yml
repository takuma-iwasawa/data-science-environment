version: "3"
services:
  chrome:  # seleniumç”¨
    image: selenium/standalone-chrome
    # restart: always
    ports:
      - 4444:4444
    volumes:
      - /dev/shm:/dev/shm
#  juman:
#    build:
#     context: ./docker/juman-knp
#     dockerfile: Dockerfile
#     args:
#      JUMANPP_VERSION: ${JUMANPP_VERSION}
#      JUMAN_VERSION: ${JUMAN_VERSION}
#      KNP_VERSION: ${KNP_VERSION}
#    image: juman-knp
##    restart: always
#    ports:
#      - "${PORT_JUMAN:-12000}:${PORT_JUMAN:-12000}"
#    depends_on:
#      - experiment
#    entrypoint:
#      - ruby
#      - /tmp/jumanpp-${JUMANPP_VERSION}/script/server.rb
#      - --cmd="jumanpp"
#      - -p=${PORT_JUMAN:-12000}
  experiment:
    build:
      context: ./docker/japanese-nlp
      dockerfile: Dockerfile
      args: 
        JUMANPP_VERSION: ${JUMANPP_VERSION}
        JUMAN_VERSION: ${JUMAN_VERSION}
        KNP_VERSION: ${KNP_VERSION}
    image: japanese-nlp
    # restart: always
    ports:
      - "${PORT_JUPYTER:-10000}:${PORT_JUPYTER:-10000}"
    volumes:
      # - .:/volume
      - ../../:/volume
    entrypoint:
      - jupyter
      - notebook
      - --port=${PORT_JUPYTER:-10000}
      - --no-browser
      - --ip=0.0.0.0
      - --allow-root
      - --NotebookApp.token=''
  mlflow:
    build:
      context: ./docker/mlflow
      dockerfile: Dockerfile
    image: mlflow
    ports:
      - "${PORT_MLFLOW:-10001}:${PORT_MLFLOW:-10001}"
    volumes:
      - ../../mlruns:/mlflow/mlruns
    depends_on:
      - experiment
    entrypoint:
      - mlflow
      - server
      - --port=${PORT_MLFLOW:-10001}
      - --host=0.0.0.0
      - --backend-store-uri=/mlflow/mlruns
      - --default-artifact-root=/mlflow/mlruns
